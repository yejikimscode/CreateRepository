---
title: "2í•™ê¸° ê¸°ë§"
output: word_document
---

```{r}
###5.24
#a. 
#(1)
X=matrix(c(1,1,1,1,1,1,4,1,2,3,3,4),ncol=2)
Y=matrix(c(16,5,10,15,13,22))
b=solve(t(X)%*%X)%*%t(X)%*%Y ; b
data5.24=read.table("CH05PR05.txt");names(data5.24)<-c("Y","X")
lm5.24 = lm(Y~X, data=data5.24); summary(lm5.24);
#(2)
resid=matrix(lm5.24$residuals) ; resid
J=matrix(c(1),nrow=6,ncol=6)
#(3)
SSR=t(b)%*%t(X)%*%Y-1/6*t(Y)%*%J%*%Y ; SSR
#(4)
SSE=t(Y)%*%Y-t(b)%*%t(X)%*%Y
SSE
#(5)
anova(lm5.24)
MSE=5.073
s2.b=MSE*solve(t(X)%*%X)
s2.b
#(6)
#ìº¡ì³ì°¸ê³ 
#(7)

#b. (a5)ì—ì„œ (1,1)ì€ s^2{b0}ì´ê³ , (1,2) and (2,1)ì€ s{b1,b0} ì´ë©°, (2,2)ëŠ” s^2{b1} ì´ë‹¤. ë”°ë¼ì„œ
# (1) s{b0,b1}=-2.103439
# (2) s^2{b0}=6.805244
sqrt(0.7423902)
# (3) s{b1}=0.8616207

#c.
H=X%*%solve(t(X)%*%X)%*%t(X)
H

#d.
I=diag(6)
s2.e=MSE*(I-H)
s2.e

##1(6.18) ìš°ìˆ˜ê³¼ì œ ë³´ë©´ì„œ í’€ê¸°
#a. Prepare a stem-and-leaf plot for each predictor variable. What information do these plots provide?  (6.9-a)
cp<-read.table("final01.txt");
names(cp) <- c("Y","X1","X2", "X3", "X4")
attach(cp)
stem(X1) 
#ê³ ë¥´ê²Œ ë¶„í¬ë˜ì–´ ìˆë‹¤.
stem(X2)
#ê³ ë¥¸í¸ì´ë‹¤.
stem(X3)
#0ì ëŒ€ ëª°ë ¤ìˆë‹¤
stem(X4)
#ì´ˆë°˜ì— ì¡°ê¸ˆ ëª°ë ¸ìœ¼ë‚˜ ê³ ë¥¸ í¸ì´ë‹¤.

#b Obtain the scatter plot matrix and the correlation matrix. Interpret these and state your principal findings. (6.9-c)
pairs(cp)
pairs(as.matrix(cp))  #ê·¸ë˜í”„ ë…¸íŠ¸ì— ì„¤ëª…
cor(cp)
# 1ê³¼ YëŠ” ìŒì˜ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ê³  ìˆë‹¤.
# X3ì€ YëŠ” ì•½í•œ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ê³  ìˆë‹¤.
# X3ì€ X4ëŠ” ì•½í•œ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ê³  ìˆë‹¤.

#c Fit regression model (1) for four predictor variables to the data. State the estimated regression function. (6.10-a)
options(scipen = 999)
lm.cp<-lm(Y~X1+X2+X3+X4, data=cp)
summary(lm.cp)  
##Y_hat=12.200585882 -0.142033644X1 + 0.282016530X2 + 0.619343503X3 + 0.000007924X4

#d Obtain the residuals and prepare a box plot of the residuals. Does the distribution appear to be fairly symmetrical?
lm.cp$resid
boxplot(lm.cp$resid)
##3-4ê°œì˜ outerê°€ ë³´ì´ì§€ë§Œ 0ì„ ì¤‘ì‹¬ìœ¼ë¡œ symmetricalí•´ ë³´ì¸ë‹¤. 

#e Plot the residuals against ğ‘ŒÌ‚, each predictor variable, and each two-factor interaction term on separate graphs. Also prepare a normal probability plot. Analyze your plots and summarize your findings.
plot(lm.cp$fitted, lm.cp$resid) #ê³ ë¥´ê²Œ ë¶„í¬ë˜ì–´ ìˆë‹¤.
plot(X1,lm.cp$resid) #ê³ ë¥´ê²Œ ë¶„í¬ë˜ì–´ ìˆë‹¤.
plot(X2,lm.cp$resid) #ê³ ë¥´ê²Œ ë¶„í¬ë˜ì–´ ìˆë‹¤.
plot(X3,lm.cp$resid) #outlierë„ ìˆê³  0ìª½ì— ì¹˜ìš°ì³ì ¸ìˆë‹¤.
plot(X4,lm.cp$resid) #ê³ ë¥´ê²Œ ë¶„í¬ë˜ì–´ ìˆë‹¤.
library(scatterplot3d)
scatterplot3d(X1,X2,lm.cp$resid)
scatterplot3d(X2,X4,lm.cp$resid)
scatterplot3d(X3,X4,lm.cp$resid)
qqnorm(lm.cp$resid)
qqline(lm.cp$resid)
#ì™„ë²½í•œ ì§ì„ ì˜ ëª¨ì–‘ì€ ì•„ë‹ˆì§€ë§Œ ë§ì´ ë²—ì–´ë‚˜ì§€ ì•ŠëŠ”ë‹¤. ë”°ë¼ì„œ eiëŠ” ì •ê·œì„±ì€ ë§Œì¡±í•œë‹¤

#f Can you conduct a formal test for lack of fit here?
# No. Xê°’ì—ì„œ ê²¹ì¹˜ëŠ” Yê°’ì´ ì—†ë‹¤. 

#g Divide the 81 cases into two groups, placing the 40 cases with the smallest fitted values ğ‘ŒÌ‚ğ‘– into group 1 and the remaining cases into group 2. Conduct the Brown-Forsythe test for constancy of the error variance, using ğ›¼ = .05. State the decision and conclusion.
ord <- order(lm.cp$fitted)
cp.ord <- cp[ord, ]
cp.lm <- lm(Y~X1+X2+X3+X4, data=cp.ord)
resd1.ord <- cp.lm$resid
d1 <- abs(resd1.ord[1:40]-median(resd1.ord[1:40]))
d2 <- abs(resd1.ord[41:81]-median(resd1.ord[41:81]))
t.test(d1, d2, var.equal = T)
qt(0.975,79)  #ğ›¼ = .05 #alpha=0.05ì¼ë•Œ t(1-a/2)ì´ë¯€ë¡œ 0.975ì“´ë‹¤.
#H0:sigma^2 is constant
#H1:sigma^2 is not constant
#t*=0.5521~F79
# -1.99045<=t<=1.99045 ë²”ìœ„ ì•ˆì— 0.5521ì´ ìˆìœ¼ë¯€ë¡œ ê¸°ê°í•˜ì§€ ì•ŠëŠ”ë‹¤.
#ë”°ë¼ì„œ sigma^2 ëŠ” constant

##2(7.27) Refer to Commercial properties Problem 1
#a Fit first-order linear regression model (2) for relating rental rates (ğ‘Œ) to property age (ğ‘‹1 ) and size (ğ‘‹4). State the fitted regression function. 
lm.cp <- lm(Y~X1+X4, data = cp)
summary(lm.cp)
# Y_hat =14.361276607-0.114467046X1+ 0.000010445X4

#b Compare the estimated regression coefficients for property age and size with the corresponding coefficients obtained in Problem 1.c. What do you find? 
lm.cp<-lm(Y~X1+X2+X3+X4, data=cp)
summary(lm.cp)
# Y_hat =  12.200585882-0.142033644X1+0.282016530X2+0.619343503X3+ 0.000007924X4
# (a) ì—ì„œ êµ¬í•œ ì¶”ì • íšŒê·€ì‹ :Y_hat =14.361276607-0.114467046X1+ 0.000010445X4
#  Problem 1.c.ì—ì„œ êµ¬í•œ ì¶”ì • íšŒê·€ì‹: Y_hat =  12.200585882-0.142033644X1+0.282016530X2+0.619343503X3+ 0.000007924X4
# X2,X3ì´ ì¶”ê°€ë˜ì b0,b1,b4ê°€ ê°ì†Œí–ˆë‹¤. 

#c Does ğ‘†ğ‘†ğ‘…(ğ‘‹4) equal ğ‘†ğ‘†ğ‘…(ğ‘‹4|ğ‘‹3) here? Does ğ‘†ğ‘†ğ‘…(ğ‘‹1) equal ğ‘†ğ‘†ğ‘…(ğ‘‹1|ğ‘‹3)? 
lm.4<-lm(Y~X4, data=cp); anova(lm.4) #ğ‘†ğ‘†ğ‘…(ğ‘‹4) = 67.775 
lm.43<-lm(Y~X3+X4, data=cp); anova(lm.43) # ğ‘†ğ‘†ğ‘…(ğ‘‹4|ğ‘‹3) =66.858 
#NO

lm.1<-lm(Y~X1, data=cp); anova(lm.1) #ğ‘†ğ‘†ğ‘…(ğ‘‹1) = 14.819 
lm.13<-lm(Y~X3+X1, data=cp); anova(lm.13) # ğ‘†ğ‘†ğ‘…(ğ‘‹1|ğ‘‹3) =13.774  
#NO

#d Refer to the correlation matrix obtained in Problem 1.b. What bearing does this have on your findings in parts (b) and (c)?
library(Hmisc)
cor(cp)
# X3ê³¼ X4ì˜ ìƒê´€ê´€ê³„ëŠ”  0.08061073ë¡œ 0.5ë³´ë‹¤ ì‘ë‹¤.
# X3ê³¼ X1ì˜ ìƒê´€ê´€ê³„ëŠ”  -0.2526635ë¡œ 0.5ë³´ë‹¤ ì‘ë‹¤.
# ë”°ë¼ì„œ X4ì™€ X1 ë§Œ ìˆëŠ” ëª¨í˜•ì—ì„œ X3ì´ ì¶”ê°€ë˜ì–´ë„ ê³„ìˆ˜ê°€ ë³€í•˜ì§€ ì•ŠëŠ”ë‹¤. SSR ë˜í•œ ë‹¬ë¼ì§€ì§€ ì•ŠëŠ”ë‹¤.

##3(8.40)
#a Fit a first-order linear regression model. Let ğ‘‹4 = 1 if hospital has medical school affiliation and 0 if not. 
sen <- read.table("final03.txt")
names(sen) <- c("N1", "X1", "X2", "Y", "N5", "X3", "N7", "X4") ; attach(sen)
lm.sen<-lm(Y~X1+X2+X3+X4, data=sen) ; summary(lm.sen)

##Yhat=1.43301 + 0.28882X1 - 0.01805X2 + 0.01995X3 - 0.28782X4

#b Estimate the effect of medical school affiliation on infection risk using a 98 percent confidence interval. Interpret your interval estimate.
# s(b4) = 0.30668 , alpha=0.02
# b4=-0.28782
qt(0.99, 108)
-0.28782-0.30668*qt(0.99,108)
-0.28782+0.30668*qt(0.99,108)
# -1.012006 < b4 < 0.4363656

#c It has been suggested that the effect of medical school affiliation on infection risk may interact with the effects of age and routine chest X-ray ratio. Add appropriate interaction terms to the regression model, fit the revised regression model, and test whether the interaction terms are helpful; use ğ›¼ = .10. State the alternatives, decision rule, and conclusion. 
lm.sen_ = lm(Y~X1+X2+X3+X4+X2:X4+X3:X4, data=sen)
summary(lm.sen_)
anova(lm.sen_)
summary(lm.sen)
anova(lm.sen)
##Yhat=-10.39627 + 0.26414X1 + 0.28868X2 -0.02383X3 
## + 5.69520X4 - 0.15576X2X3 + 0.02406X3X4
##H0:b5=b6=0 / H1:not both b5, b6 are equal to 0
##SSR(X2X4,X3X4|X1,X2,X3,X4)
##=SSE(X1,X2,X3,X4)-SSE(X1,X2,X3,X4,X2X4,X3X4)
127.243-122.047
(5.196/2)/(122.047/106)
##F*=(5.196/2)/(122.047/106)=2.256409
qf(0.9, 2, 106) #=2.3533
##alpha=0.1, df=108-2
##F*>2.3533, H0 ê¸°ê°X, b5=b6=0



##4(9.15)  (9.16)
# a. Obtain the scatter plot matrix. Also obtain the correlation matrix of the ğ‘‹ variables. What do the scatter plots suggest about the nature of the functional relationship between the response variable ğ‘Œ and each predictor variable? Discuss. Are any serious multicollinearity problems evident? Explain.
kf<-read.table("final04.txt");
names(kf) <- c("Y","X1","X2", "X3")
attach(kf)
pairs(kf)
pairs(as.matrix(kf))
cor(kf)
#Yì— X1ê³¼ X2ëŠ” ìŒì˜ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ê³  ìˆê³  X3ëŠ” ì–‘ì˜ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ê³  ìˆë‹¤.
# X1ì€ Yì™€ ê°•í•œ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ê³  ìˆë‹¤.

# b. Fit the multiple regression function containing the three predictor variables as first-order terms. Does it appear that all predictor variables should be retained?
lm.kf<-lm(Y~X1+X2+X3, data=kf)
summary(lm.kf)

#Y_hat=120.0473 - 39.9393X1 - 0.7368X2 + 0.7764X3
#ê°ê°ì˜ predictorì˜ p-valueê°€ 0ì— ê·¼ì‚¬í•˜ë‹¤. ëª¨ë‘ regressionì— í¬í•¨ë˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.

# c. Using first-order and second-order terms for each of the three predictor variables (centered around the mean) in the pool of potential ğ‘‹ variables (including cross products of the first-order terms), find the three best hierarchical subset regression models according to the ğ¶ğ‘ criterion.
X1=kf$X1-mean(kf$X1)
X2=kf$X2-mean(kf$X2)
X3=kf$X3-mean(kf$X3)
reg0=lm(Y~X1+X2+X3+X1:X2+X3^2, data=kf) ; summary(reg0)
reg1=lm(Y~X1+X2+X3+X1:X2+X2^2+X3^2, data=kf) ; summary(reg1)
reg2=lm(Y~X1+X2+X3+X1:X3+X3^2, data=kf) ; summary(reg2)
reg3=lm(Y~X1+X2+X3+X1:X2+X1:X3+X3^2, data=kf) ; summary(reg3)
reg4=lm(Y~X1+X2+X3+X1:X2+X2^2+X3^2, data=kf) ; summary(reg4)
##cpê°’ êµ¬í•˜ëŠ”ë²• ì°¾ê¸°

library(car); extractAIC(reg2, scale=sigmaHat(reg3)^2)
# reg3: ê°€ì¥ í° ëª¨í˜• ë„£ì–´ì£¼ëŠ” ê²ƒ. pë³´ë‹¤ ì‘ìœ¼ë©´ ì¢‹ì€ê²ƒ. ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ
extractAIC(reg2, scale=sigmaHat(reg3)^2)
extractAIC(reg1, scale=sigmaHat(reg3)^2)
extractAIC(reg2, scale=sigmaHat(reg3)^2)
extractAIC(reg3, scale=sigmaHat(reg3)^2)
extractAIC(reg4, scale=sigmaHat(reg3)^2)

# d. Is there much difference in ğ¶ğ‘ for the three best subset models?
##no. Cpê°’ì´ ë§ì´ ë‹¤ë¥´ì§€ ì•Šê¸° ë•Œë¬¸ì´ë‹¤.

##5(8.21)   #ë…¸íŠ¸(ì²´ê·¸)
#a. Develop the response function for each type of protection category.
#b. For each of the following questions, specify the alternatives ğ»0 and ğ»ğ›¼ for the appropriate test: (1) With ğ‘‹1 fixed, does wearing a bump cap reduce the expected severity of injury as compared with wearing no protection? (2) With ğ‘‹1 fixed, is the expected severity of injury the same when wearing a hard hat as when wearing a bump cap?

##6(8.24) 
# a. Plot the sample data for the two populations as a symbolic scatter plot. Does the regression relation appear to be the same for the two populations?
final06=read.table("final06.txt")
names(final06)=c("Y","X1","X2")
pairs(cp)
ord=order(final06$X2)
final06.2=final06[ord, ]
plot(final06.2$X1[1:48], final06.2$Y[1:48]) #X2=0ì¼ë–„
plot(final06.2$X1[49:64], final06.2$Y[49:64]) #X2=1ì¼ë–„
##X1ê³¼ YëŠ” ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤.
##X2ì™€ YëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ë¡œ plotë§Œìœ¼ë¡œëŠ” íŒë‹¨ ë¶ˆê°€í•˜ë‹¤.
##X2=0, X2=1ì¼ ë•Œ ëª¨ë‘ X1ê³¼ YëŠ” ì–‘ì˜ ìƒê´€ê´€ê³„ë¥¼ ë³´ì¸ë‹¤.

# b. Test for identity of the regression functions for dwellings on corner lots and dwellings in other locations: control the risk of Typeâ… error at 0.05. State the alternatives, decision rule, and conclusion.
lm.final06.1=lm(Y~X1+X2+X1*X2, data=final06);summary(lm.final06.1)
anova(lm.final06.1)

lm.final06.2=lm(Y~X1, data=final06);summary(lm.final06.2)
anova(lm.final06.2)

1475.3-90901
(566.2/2)/(909.1/60)
qf(0.95, 2, 60) 
1-pf(18.6844, 2, 60)
##Yhat=-126.9052 + 2.7759X1 + 76.0215X2 - 1.1075X1*X2
##H0:b2=b3=0 / H1:not both b2, b3 are equal to 0
##SSR(X2,X1:X2|X1)=366.2
##test statistic F*=18.6844 / p-value=0.0000005
#=3.150411
##F*>3.150411 ì´ë¯€ë¡œ H0ê¸°ê°
##not both b2, b3 are equal to 0


# c. Plot the estimated regression functions for the two populations and describe the nature of the differences between them. 
fit.final06=lm(Y~X1+X2+X1*X2, data=final06)
summary(fit.final06)

plot(final06$X1, final06$Y)
-126.9052+76.0215
2.7759-1.1075
abline(-50.8837,1.6684)  #X2=1ì¼ë•Œ
abline(-126.9052,2.7759)  #X2=0ì¼ë•Œ

##êµí˜¸ì‘ìš©ìœ¼ë¡œ ì¸í•´ X2ê°€ ë‹¤ë¥¸ ê°’ìœ¼ë¡œ ê³ ì •ë  ê²½ìš°,
##ê¸°ìš¸ê¸°ì™€ interceptê°€ ëª¨ë‘ ë‹¬ë¼ì§„ë‹¤.
##Yhat=-126.9052 + 2.7759X1 (X2=0) : noncorner lots
##Yhat=-50.8837 + 1.6684 (X2=1) : corner lots


```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
