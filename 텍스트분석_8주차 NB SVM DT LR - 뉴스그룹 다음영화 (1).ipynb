{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영어 문서 분류\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 뉴스그룹 데이터 준비 및 특성 추출\n",
    "20 뉴스그룹 데이터셋은 텍스트 마이닝에서 문서 분류의 성능을 측정하기 위해 가장 많이 사용되는 데이터셋 중 하나   \n",
    "뉴스그룹은 언론에서 출판되는 기사라기 보다는 게시판에 올라온 사용자들의 포스트임  \n",
    "뉴스그룹마다 특정 주제가 있고 사용자는 그에 맞는 뉴스를 올리거나 읽을 수 있음\n",
    "\n",
    "\n",
    "\n",
    " http://scikit-learn.org/0.19/datasets/twenty_newsgroups.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set size: 2034\n",
      "#Test set size: 1353\n",
      "#Selected categories: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
      "#Train labels: {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "#20개의 토픽 중 선택하고자 하는 토픽을 리스트로 생성\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']  # 무신론, 종교, 컴퓨터그래픽, 과학\n",
    "\n",
    "#학습 데이터셋을 가져옴\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "#메일 내용에서 hint가 되는 부분을 삭제 - 순수하게 내용만으로 분류\n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "#검증 데이터셋을 가져옴\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', \n",
    "                                     remove=('headers', 'footers', 'quotes'),\n",
    "                                     categories=categories)\n",
    "\n",
    "print('#Train set size:', len(newsgroups_train.data))  #.data: 텍스트 내용 반환 \n",
    "print('#Test set size:', len(newsgroups_test.data))\n",
    "print('#Selected categories:', newsgroups_train.target_names)\n",
    "print('#Train labels:', set(newsgroups_train.target))  #.target: 숫자로 표시된 라벨 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set text samples: Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "#Train set label smaples: 1\n",
      "#Test set text samples: TRry the SKywatch project in  Arizona.\n",
      "#Test set label smaples: 2\n"
     ]
    }
   ],
   "source": [
    "print('#Train set text samples:', newsgroups_train.data[0])\n",
    "print('#Train set label smaples:', newsgroups_train.target[0])\n",
    "print('#Test set text samples:', newsgroups_test.data[0])\n",
    "print('#Test set label smaples:', newsgroups_test.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "(2034,)\n",
      "Train set dimension: (2034, 2000)\n",
      "Test set dimension: (1353, 2000)\n"
     ]
    }
   ],
   "source": [
    "X_train = newsgroups_train.data   #학습 데이터셋 문서\n",
    "y_train = newsgroups_train.target #학습 데이터셋 라벨\n",
    "\n",
    "X_test = newsgroups_test.data     #검증 데이터셋 문서\n",
    "y_test = newsgroups_test.target   #검증 데이터셋 라벨\n",
    "\n",
    "print(type(newsgroups_train.data))\n",
    "print(type(newsgroups_train.target))\n",
    "print(newsgroups_train.target.shape)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=2000, min_df=5, max_df=0.5)\n",
    "# min_df: 문서에 거의 나타나지 않는 예외적인 단어 제외, 5는 5개 미만의 문서에서 나타나는 단어 제외\n",
    "# max_df: 많은 문서에 공통으로 나타나는 단어들을 제외, 0.5는 코퍼스 문서의 50%를 초과해 나타나는 단어들을 제외\n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train) # train set을 변환\n",
    "print('Train set dimension:', X_train_cv.shape) \n",
    "X_test_cv = cv.transform(X_test) # test set을 변환\n",
    "print('Test set dimension:', X_test_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 : 0, 000 : 0, 01 : 0, 04 : 0, 05 : 0, 10 : 0, 100 : 0, 1000 : 0, 11 : 0, 12 : 0, 128 : 0, 129 : 0, 13 : 0, 130 : 0, 14 : 0, 15 : 0, 16 : 0, 17 : 0, 18 : 0, 19 : 0, 1987 : 0, 1988 : 0, 1989 : 0, 1990 : 0, 1991 : 0, 1992 : 0, 1993 : 0, 20 : 0, 200 : 0, 202 : 0, 21 : 0, 22 : 0, 23 : 0, 24 : 0, 25 : 0, 256 : 0, 26 : 0, 27 : 0, 28 : 0, 2d : 0, 30 : 0, 300 : 0, 31 : 0, 32 : 0, 33 : 0, 34 : 0, 35 : 0, 39 : 0, 3d : 0, 40 : 0, 400 : 0, 42 : 0, 45 : 0, 50 : 0, 500 : 0, 60 : 0, 600 : 0, 65 : 0, 70 : 0, 75 : 0, 80 : 0, 800 : 0, 90 : 0, 900 : 0, 91 : 0, 92 : 0, 93 : 0, 95 : 0, _the : 0, ability : 0, able : 1, abortion : 0, about : 1, above : 0, absolute : 0, absolutely : 0, ac : 0, accept : 0, acceptable : 0, accepted : 0, access : 0, according : 0, account : 0, accurate : 0, across : 0, act : 0, action : 0, actions : 0, active : 0, activities : 0, activity : 0, acts : 0, actual : 0, actually : 0, ad : 0, add : 0, added : 0, addition : 0, additional : 0, address : 0, "
     ]
    }
   ],
   "source": [
    "for word, count in zip(cv.get_feature_names()[:100], X_train_cv[0].toarray()[0, :100]):\n",
    "    print(word, ':', count, end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝과 문서 분류 과정에 대한 이해\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나이브 베이즈 분류기(Naive Bayse Classifier)를 이용한 문서 분류\n",
    "\n",
    "1. http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.824\n",
      "Test set score: 0.732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB #sklearn이 제공하는 MultinomialNB 를 사용\n",
    "NB_clf = MultinomialNB() # 분류기 선언\n",
    "\n",
    "NB_clf.fit(X_train_cv, y_train) # 학습, X_train_cv:(2034, 2000), y_train:(2034,)\n",
    "\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train))) #train set에 대한 예측정확도를 확인\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test))) #test set에 대한 예측정확도를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#First document and label in test data: TRry the SKywatch project in  Arizona. 2\n",
      "#Second document and label in test data: The Vatican library recently made a tour of the US.\n",
      " Can anyone help me in finding a FTP site where this collection is \n",
      " available. 1\n",
      "#Predicted labels: [2 1]\n",
      "#Predicted categories: sci.space comp.graphics\n"
     ]
    }
   ],
   "source": [
    "print('#First document and label in test data:', X_test[0], y_test[0])\n",
    "print('#Second document and label in test data:', X_test[1], y_test[1])\n",
    "\n",
    "pred = NB_clf.predict(X_test_cv[:2])\n",
    "\n",
    "print('#Predicted labels:', pred)\n",
    "print('#Predicted categories:', newsgroups_train.target_names[pred[0]], newsgroups_train.target_names[pred[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*성능 개선 방법*  \n",
    "1. 카운트 벡터 생성시 max_features, min_df, max_df 등 인자 값 변경  \n",
    "2. 모델 복잡도를 조절하는 alpha 등 나이브베이즈의 인자 값 변경  \n",
    "3. 나이브베이즈가 아닌 다른 머신러닝 알고리즘 시도  \n",
    "4. CountVectorizer 대신 TfidfVectorizer 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.862\n",
      "Test set score: 0.741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#CountVectorizer와 동일한 인수를 사용\n",
    "tfidf = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.5) \n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train set을 변환\n",
    "X_test_tfidf = tfidf.transform(X_test) # test set을 변환\n",
    "\n",
    "NB_clf.fit(X_train_tfidf, y_train) #tfidf train set을 이용하여 분류기(classifier)를 새로 학습\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train))) #train set에 대한 예측정확도를 확인\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test))) #test set에 대한 예측정확도를 확인\n",
    "\n",
    "# 0.732 => 0.741"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: you, not, are, be, this, have, as, what, they, if\n",
      "comp.graphics: you, on, graphics, this, have, any, can, or, with, thanks\n",
      "sci.space: space, on, you, be, was, this, as, they, have, are\n",
      "talk.religion.misc: you, not, he, are, as, this, be, god, was, they\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def top10_features(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        # 역순으로 정렬하기 위해 계수에 음수를 취해서 정렬 후 앞에서부터 10개의 값을 반환\n",
    "        top10 = np.argsort(-classifier.coef_[i])[:10]\n",
    "        # 카테고리와 영향이 큰 특성 10개를 출력\n",
    "        print(\"%s: %s\" % (category, \", \".join(feature_names[top10])))\n",
    "\n",
    "top10_features(NB_clf, tfidf, newsgroups_train.target_names)\n",
    "\n",
    "# you, are, this 와 같은 단어들이 모든 카테고리에 동시에 있으면서 높은 영향을 미친다는 점이 의아함.\n",
    "# MultinomialNB에 대해 sklearn 1.1 버전부터는 coef_ 가 지원되지 않음.\n",
    "# coef_를 이용한 단어의 영향에 대한 분석은 로지스틱 회귀분석 계열에서 사용하기를 권장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀분석을 이용한 문서 분류\n",
    "\n",
    "1: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.930\n",
      "Test set score: 0.734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression #sklearn이 제공하는 logistic regression을 사용\n",
    "\n",
    "#count vector에 대해 regression을 해서 NB와 비교\n",
    "LR_clf = LogisticRegression() #분류기 선언\n",
    "LR_clf.fit(X_train_tfidf, y_train) # train data를 이용하여 분류기를 학습\n",
    "print('Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train))) # train data에 대한 예측정확도 \n",
    "print('Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test))) # test data에 대한 예측정확도\n",
    "\n",
    "# 학습 데이터와 평가 데이터에 대한 성능의 차이가 나이브베이즈보다 로지스틱 회귀분석에서 더욱 큼\n",
    "# 로지스틱 회귀분석에서 과적합이 일어났을 가능성이 있음을 의미\n",
    "\n",
    "# 과적합을 방지하기 위해 특성의 수를 줄이는 것도 방법이지만(현재 특성의 수 2,000개, 학습 데이터 수 2,034개)\n",
    "# 텍스트 분석에서는 특성이 많음에도 좋은 성능을 보이는 경우가 많으므로\n",
    "\n",
    "# 과적합을 방지하는 방법으로 정규화(릿지, 라쏘) 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 릿지 회귀(ridge regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.960\n",
      "Test set score: 0.735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "ridge_clf = RidgeClassifier() #릿지 분류기 선언\n",
    "ridge_clf.fit(X_train_tfidf, y_train) #학습\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "# 테스트셋에 대한 성능이 아주 조금 나아지기는 했지만 과적합이 더 심해진 것처럼 보임\n",
    "# => alpha 조정해보기: 학습 데이터셋을 분리해서 검증 데이터셋을 만들고 검증 데이터셋에 대해 성능이 최고가 되는 alpha 선택  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max alpha 1.600 at max validation score 0.826\n"
     ]
    }
   ],
   "source": [
    "# RidgeClassifier의 인자 alpha 최적값 찾기 \n",
    "# alpha는 정규화의 정도를 조절, alpha가 커질수록 정규화의 비중이 커져서 계수의 변화를 더 많이 억제\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_ridge, X_val_ridge, y_train_ridge, y_val_ridge = train_test_split(\n",
    "    X_train_tfidf, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "max_score = 0\n",
    "max_alpha = 0\n",
    "\n",
    "for alpha in np.arange(0.1, 10, 0.1): # alpha를 0.1부터 10까지 0.1씩 증가\n",
    "    ridge_clf = RidgeClassifier(alpha=alpha) #릿지 분류기 선언\n",
    "    ridge_clf.fit(X_train_ridge, y_train_ridge) #학습\n",
    "    score = ridge_clf.score(X_val_ridge, y_val_ridge) #검정 데이터셋에 대해 정확도를 측정\n",
    "    if score > max_score: #정확도가 이전의 정확도 최대값보다 크면 최대값을 변경한다.\n",
    "        max_score = score\n",
    "        max_alpha = alpha\n",
    "print('Max alpha {:.3f} at max validation score {:.3f}'.format(max_alpha, max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.948\n",
      "Test set score: 0.739\n"
     ]
    }
   ],
   "source": [
    "ridge_clf = RidgeClassifier(alpha=1.6) #릿지 분류기 선언\n",
    "ridge_clf.fit(X_train_tfidf, y_train) #학습\n",
    "\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "# 기존의 로지스틱 회귀분석보다는 좋은 성능이지만 나이브베이즈에는 못미치는 성능\n",
    "# 모형간 차이는 주어진 데이터와 상황에 따라 달라서 일반화하기는 어렵지만 나이브베이즈가 무시못할 성능이라는 점~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: bobby, religion, atheism, atheists, motto, punishment, islam, deletion, islamic, satan\n",
      "comp.graphics: graphics, computer, 3d, file, image, hi, 42, using, screen, looking\n",
      "sci.space: space, orbit, nasa, spacecraft, moon, sci, launch, flight, funding, idea\n",
      "talk.religion.misc: christian, christians, fbi, blood, order, jesus, objective, children, christ, hudson\n"
     ]
    }
   ],
   "source": [
    "top10_features(ridge_clf, tfidf, newsgroups_train.target_names)\n",
    "\n",
    "# 나이브베이즈에 비해 의미있는 단어들 => 로지스틱 회귀분석 계열의 장점\n",
    "# 결과를 설명하고 해석하기에 용이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라쏘 회귀분석(lasso regression)을 이용한 특성 선택(feature selection)\n",
    "\n",
    "1. http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.819\n",
      "#Test set score: 0.724\n",
      "#Used features count: 437 out of 2000\n"
     ]
    }
   ],
   "source": [
    "# Lasso는 동일한 LogisticRegression을 사용하면서 'l1' 과 'liblinear' 로 지정\n",
    "# C는 alpha의 역수로 C가 커질수록 정규화는 약해짐\n",
    "\n",
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=1) \n",
    "\n",
    "lasso_clf.fit(X_train_tfidf, y_train) # train data로 학습\n",
    "\n",
    "print('#Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "# 계수(coefficient) 중에서 0이 아닌 것들의 개수를 출력\n",
    "print('#Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: bobby, atheism, atheists, islam, religion, islamic, motto, atheist, satan, vice\n",
      "comp.graphics: graphics, image, 3d, file, computer, hi, video, files, looking, sphere\n",
      "sci.space: space, orbit, launch, nasa, spacecraft, flight, moon, dc, shuttle, solar\n",
      "talk.religion.misc: fbi, christian, christians, christ, order, jesus, children, objective, context, blood\n"
     ]
    }
   ],
   "source": [
    "top10_features(lasso_clf, tfidf, newsgroups_train.target_names)\n",
    "\n",
    "# 릿지 회귀분석보다 이 단어들이 각 카테고리를 더 잘 설명하는 것으로 보임\n",
    "# 라쏘는 특성의 수를 줄이고 특성에 대한 설명을 더 잘하기 위해서도 많이 사용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결정트리 등을 이용한 문서 분류 방법\n",
    "\n",
    "1. https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "2. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "3. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Decision Tree train set score: 0.977\n",
      "#Decision Tree test set score: 0.536\n",
      "#Random Forest train set score: 0.977\n",
      "#Random Forest test set score: 0.685\n",
      "#Gradient Boosting train set score: 0.933\n",
      "#Gradient Boosting test set score: 0.696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=7)\n",
    "tree.fit(X_train_tfidf, y_train)\n",
    "print('#Decision Tree train set score: {:.3f}'.format(tree.score(X_train_tfidf, y_train)))\n",
    "print('#Decision Tree test set score: {:.3f}'.format(tree.score(X_test_tfidf, y_test)))\n",
    "\n",
    "forest = RandomForestClassifier(random_state=7)\n",
    "forest.fit(X_train_tfidf, y_train)\n",
    "print('#Random Forest train set score: {:.3f}'.format(forest.score(X_train_tfidf, y_train)))\n",
    "print('#Random Forest test set score: {:.3f}'.format(forest.score(X_test_tfidf, y_test)))\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=7)\n",
    "gb.fit(X_train_tfidf, y_train)\n",
    "print('#Gradient Boosting train set score: {:.3f}'.format(gb.score(X_train_tfidf, y_train)))\n",
    "print('#Gradient Boosting test set score: {:.3f}'.format(gb.score(X_test_tfidf, y_test)))\n",
    "\n",
    "# 학습 데이터에 대한 결과 높음. 결정트리가 일반적으로 학습 데이터에 과적합되는 성향이 매우 강함.\n",
    "# 전체적인 성능은 좋지 않음. 최적화를 위한 하이퍼 파라미터 탐색을 안한 원인도 있지만,\n",
    "# 문서 분류의 경우 결정트리 기반 알고리즘의 성능이 전반적으로 좋지 않은 경향이 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space: 0.126, graphics: 0.080, atheism: 0.024, thanks: 0.023, file: 0.021, orbit: 0.020, jesus: 0.018, god: 0.018, hi: 0.017, nasa: 0.015, image: 0.015, files: 0.014, christ: 0.010, moon: 0.010, bobby: 0.010, launch: 0.010, looking: 0.010, christian: 0.010, atheists: 0.009, christians: 0.009, fbi: 0.009, 3d: 0.008, you: 0.008, not: 0.008, islamic: 0.007, religion: 0.007, spacecraft: 0.007, flight: 0.007, computer: 0.007, islam: 0.007, ftp: 0.006, color: 0.006, software: 0.005, atheist: 0.005, card: 0.005, people: 0.005, koresh: 0.005, his: 0.005, kent: 0.004, sphere: 0.004, "
     ]
    }
   ],
   "source": [
    "sorted_feature_importances = sorted(zip(tfidf.get_feature_names(), gb.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "for feature, value in sorted_feature_importances[:40]:\n",
    "    print('%s: %.3f' % (feature, value), end=', ')\n",
    "\n",
    "# 그레디언트 부스팅 분류기의 특성 중요도 coef_ 대신 feature_importances_ 제공\n",
    "# 결정트리에서는 성격이 비슷한 두 단어 중 하나가 분류에 먼저 사용되면 다른 단어는 상대적으로 중요도가 떨어짐.\n",
    "# 이 경우 로지스틱 회귀분석에서는 두 단어가 비슷한 계숫값을 가짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능을 높이기 위한 방법들\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.930\n",
      "#Test set score: 0.751\n"
     ]
    }
   ],
   "source": [
    "# 정규표현식 토크나이저 사용, NLTK 불용어 사전으로 불용어 제거, 포터 스테머로 스테밍\n",
    "# 이 토큰화 결과를 TfidfVectorizer에 입력으로 사용\n",
    "# 얻은 특성 벡터로 로지스틱 회귀분석 실시후 결과 비교\n",
    "\n",
    "# 필요한 library들을 import\n",
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "\n",
    "RegTok = RegexpTokenizer(\"[\\w']{3,}\") # 정규포현식으로 토크나이저를 정의\n",
    "english_stops = set(stopwords.words('english')) #영어 불용어를 가져옴\n",
    "\n",
    "def tokenizer(text):\n",
    "    tokens = RegTok.tokenize(text.lower()) \n",
    "    # stopwords 제외\n",
    "    words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
    "    # portr stemmer 적용\n",
    "    features = (list(map(lambda token: PorterStemmer().stem(token),words)))\n",
    "    return features\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenizer, max_features=2000, min_df=5, max_df=0.5) # 새로 정의한 토크나이저 사용\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train set을 변환\n",
    "X_test_tfidf = tfidf.transform(X_test) # test set을 변환\n",
    "\n",
    "#tfidf vector를 이용해서 분류기 학습\n",
    "LR_clf = LogisticRegression() #분류기 선언\n",
    "LR_clf.fit(X_train_tfidf, y_train) # train data를 이용하여 분류기를 학습\n",
    "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train))) # train data에 대한 예측정확도 \n",
    "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test))) # test data에 대한 예측정확도\n",
    "\n",
    "# 0.739 => 0.751 향상 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LR_clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set dimension: (2034, 20085)\n",
      "#Test set dimension: (1353, 20085)\n",
      "#Train set score: 0.968\n",
      "#Test set score: 0.768\n",
      "#Train set score: 0.971\n",
      "#Test set score: 0.793\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터에 비해 특성의 수가 많은, 일반적으로 과적합이 발생하는 조건인데도 \n",
    "# 문서 분류는 별 문제 없는 경우가 많음 => 특성의 수를 제한하지 않음\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenizer)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train set을 변환\n",
    "print('#Train set dimension:', X_train_tfidf.shape) # 실제로 몇개의 특성이 사용되었는지 확인\n",
    "X_test_tfidf = tfidf.transform(X_test) # test set을 변환\n",
    "print('#Test set dimension:', X_test_tfidf.shape)\n",
    "\n",
    "# 그리드서치로 적정 alpha 값 구함\n",
    "ridge_clf = RidgeClassifier(alpha=2.4)\n",
    "ridge_clf.fit(X_train_tfidf, y_train) #학습\n",
    "print('#Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "NB_clf = MultinomialNB(alpha=0.01) # 분류기 선언\n",
    "NB_clf.fit(X_train_tfidf, y_train) #train set을 이용하여 분류기(classifier)를 학습\n",
    "print('#Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train))) #train set에 대한 예측정확도를 확인\n",
    "print('#Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test))) #test set에 대한 예측정확도를 확인\n",
    "\n",
    "# 릿지 회귀분석이 꽤 향상됐지만 나이브베이즈가 가장 높은 결과를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 카운트 기반의 문제점과 N-gram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 11483)\n"
     ]
    }
   ],
   "source": [
    "# BOW 방식을 그대로 쓰면서도 단어가 쓰여진 순서를 제한적으로나마 반영할 수 있는 N-gram 추가 방법 \n",
    "# 특성의 수가 너무 많아지면 과적합 등 부작용이 있으므로 일반적으로 3-gram 정도까지 사용\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "tfidf = TfidfVectorizer(token_pattern= \"[a-zA-Z']{3,}\", # 토큰화를 위한 정규식\n",
    "                        decode_error ='ignore', # 주어진 인코딩 방식이 아닌 문자가 포함되어 있을 때 무시 \n",
    "                        lowercase=True, \n",
    "                        stop_words = stopwords.words('english'), \n",
    "                        max_df=0.5,\n",
    "                        min_df=2)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "# 유니그램일 때 단어 수 11483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.976\n",
      "Test set score: 0.766\n"
     ]
    }
   ],
   "source": [
    "# N-gram을 사용하면 변수의 수가 늘어나고 이로 인해 과적합 우려가 있으므로 릿지 회귀분석 사용 \n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_clf = RidgeClassifier() #릿지 분류기 선언\n",
    "ridge_clf.fit(X_train_tfidf, y_train) #학습\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 26550)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(token_pattern= \"[a-zA-Z']{3,}\", \n",
    "                        decode_error ='ignore', \n",
    "                        lowercase=True, \n",
    "                        stop_words = stopwords.words('english'),\n",
    "                        ngram_range=(1, 2), # 시작 N값과 끝 N값 설정. 유니그램과 바이그램 모두 사용. 바이그램만 사용 시 (2, 2)\n",
    "                        max_df=0.5,\n",
    "                        min_df=2)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "# 특성의 수가 11483 => 26550 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-gram samples: [\"'cause can't\", \"'em better\", \"'expected errors'\", \"'karla' next\", \"'nodis' password\", \"'official doctrine\", \"'ok see\", \"'sci astro'\", \"'what's moonbase\", 'aas american']\n",
      "Train set score: 0.976\n",
      "Test set score: 0.773\n"
     ]
    }
   ],
   "source": [
    "# 바이그램 특성 이름 일부 출력 및 릿지 수행\n",
    "\n",
    "bigram_features = [f for f in tfidf.get_feature_names() if len(f.split()) > 1]\n",
    "print('bi-gram samples:', bigram_features[:10])\n",
    "\n",
    "ridge_clf.fit(X_train_tfidf, y_train) #학습\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "# 유니그램만 사용 정확도 76.6% => 유니+바이 그램 사용 정확도 77.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 32943)\n",
      "tri-gram samples: [\"'em better shots\", \"'expected errors' basically\", \"'karla' next one\", \"'nodis' password also\", \"'official doctrine think\", \"'ok see warning\", \"'what's moonbase good\", 'aas american astronautical', 'ability means infallible', 'able accept donations']\n",
      "Train set score: 0.976\n",
      "Test set score: 0.775\n"
     ]
    }
   ],
   "source": [
    "# 트라이그램도 추가\n",
    "\n",
    "tfidf = TfidfVectorizer(token_pattern= \"[a-zA-Z']{3,}\", \n",
    "                        decode_error ='ignore', \n",
    "                        lowercase=True, \n",
    "                        stop_words = stopwords.words('english'),\n",
    "                        ngram_range=(1, 3),   # 유니그램~트라이그램\n",
    "                        max_df=0.5,\n",
    "                        min_df=2)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "trigram_features = [f for f in tfidf.get_feature_names() if len(f.split()) > 2]\n",
    "print('tri-gram samples:', trigram_features[:10])\n",
    "\n",
    "ridge_clf.fit(X_train_tfidf, y_train) #학습\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "# 77.3% => 77.5% 로 아주 약간 상승\n",
    "# N-gram 추가가 근본적인 해결책이라고 보기는 어렵지만 \n",
    "# 상황에 따라 N-gram이 필요한 경우가 있으므로 개념과 사용법은 알아두는 것이 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글 문서의 분류\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.10.29</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.26</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.24</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이 정도면 볼만하다고 할 수 있음!</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.22</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>재미있다</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.20</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating        date  \\\n",
       "0                             돈 들인건 티가 나지만 보는 내내 하품만       1  2018.10.29   \n",
       "1       몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.      10  2018.10.26   \n",
       "2  이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...       8  2018.10.24   \n",
       "3                                이 정도면 볼만하다고 할 수 있음!       8  2018.10.22   \n",
       "4                                               재미있다      10  2018.10.20   \n",
       "\n",
       "    title  \n",
       "0  인피니티 워  \n",
       "1  인피니티 워  \n",
       "2  인피니티 워  \n",
       "3  인피니티 워  \n",
       "4  인피니티 워  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/daum_movie_review.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "돈 들인건 티가 나지만 보는 내내 하품만\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(df.review[0])\n",
    "print(type(df.review))\n",
    "print(type(df.title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "신과함께      4947\n",
       "택시운전사     2322\n",
       "인피니티 워    2042\n",
       "범죄도시      1939\n",
       "곤지암       1547\n",
       "라라랜드      1150\n",
       "코코         778\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.value_counts()\n",
    "\n",
    "# 영화별 리뷰 수 차이 => 불균형 데이터셋. 해결 방법으로 언더샘플링, 오버샘플링 등이 있지만 이대로 분류 진행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set size: 11043\n",
      "#Test set size: 3682\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.review, df.title, random_state=0)\n",
    "# 비율을 지정하지 않으면 75:25로 분할됨\n",
    "\n",
    "print('#Train set size:', len(X_train)) # 실제로 몇개의 특성이 사용되었는지 확인\n",
    "print('#Test set size:', len(X_test))\n",
    "\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['몰입', '할수밖에', '없다', '.', '어렵게', '생각', '할', '필요없다', '.', '내', '가', '전투', '에', '참여', '한', '듯', '손', '에', '땀', '이남', '.']\n",
      "['몰입', '생각', '내', '전투', '참여', '듯', '손', '땀', '이남']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt #konlpy에서 Twitter 형태소 분석기를 import\n",
    "#from konlpy.tag import Twitter #konlpy에서 Twitter 형태소 분석기를 import\n",
    "okt = Okt()\n",
    "\n",
    "print(okt.morphs(X_train[1])) #둘째 리뷰에 대해 형태소 단위로 tokenize\n",
    "print(okt.nouns(X_train[1])) #둘째 리뷰에서 명사만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.756\n",
      "#Test set score: 0.694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Twitter 형태소분석기에서 명사만 추출하는 함수를 tokenizer로 이용\n",
    "tfidf = TfidfVectorizer(tokenizer=okt.nouns, max_features=2000, min_df=5, max_df=0.5) \n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train data 변환 -> tfidf vector\n",
    "X_test_tfidf = tfidf.transform(X_test) # test data 변환 -> tfidf vector\n",
    "\n",
    "# logistic regression 분류기 선언\n",
    "clf = LogisticRegression(max_iter=1000) # 충분한 학습을 위해 max_iter를 1,000으로 설정, 기본은 100(기본으로 했을 때 warning 발생)\n",
    "clf.fit(X_train_tfidf, y_train) # 분류기 학습\n",
    "print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train))) # train data 예측정확도\n",
    "print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) # test data 예측정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제영화제목, 예측한 제목, 리뷰\n",
      "('범죄도시', '신과함께', '오랜만에 잼나는 영화 봤습니다.  다음에 더 재미있는 영화 기대하겠습니다.')\n",
      "('범죄도시', '범죄도시', '조연들이 눈에 박힌다. 간만에 집중 ㅎ')\n",
      "('코코', '코코', '대감동을 선사. 인사이드 아웃을 잇는 픽사의 감동스토리. 신과함께의 멕시코판이라고나할까요??')\n",
      "('신과함께', '신과함께', '돈이 안아까웠던 영화ᆞᆞ  정말 좋았다')\n",
      "('신과함께', '신과함께', '역시 김용화감독이 영화는 잘 만들어요. 이제 VFX 제작 부문도 헐리우드 수준 이상입니다.')\n",
      "('택시운전사', '택시운전사', '민주화를 위해 힘써주신 분들께 감사하는 마음으로 살아야겠다.')\n",
      "('신과함께', '신과함께', '잠만 자다 왔음')\n",
      "('신과함께', '신과함께', '오랜만에 잼있고 좋은 영화를 봤다')\n",
      "('범죄도시', '신과함께', '잼남')\n",
      "('범죄도시', '인피니티 워', '대박~~')\n"
     ]
    }
   ],
   "source": [
    "print('실제영화제목, 예측한 제목, 리뷰')\n",
    "for content in zip(y_test[:10], clf.predict(X_test_tfidf[:10]), X_test[:10]):\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능을 개선하기 위한 노력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.777\n",
      "#Test set score: 0.695\n"
     ]
    }
   ],
   "source": [
    "# 명사뿐만 아니라 모든 품사 사용 \n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=okt.morphs, max_features=2000, min_df=5, max_df=0.5) # 명사 대신 모든 형태소를 사용\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000) # 충분한 학습을 위해 max_iter를 1,000으로 설정, 기본은 100\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train))) # train data 예측정확도\n",
    "print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) # test data 예측정확도\n",
    "\n",
    "# 명사만 69.4% => 모든 품사 69.5%  별 차이 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.784\n",
      "#Test set score: 0.712\n"
     ]
    }
   ],
   "source": [
    "# 명사, 동사, 형용사만 사용 tokenizer 정의\n",
    "\n",
    "def twit_tokenizer(text): #전체를 다 사용하는 대신, 명사, 동사, 형용사를 사용\n",
    "    target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in okt.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "    return result\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, max_features=2000, min_df=5, max_df=0.5) #명사, 동사, 형용사를 이용하여 tfidf 생성\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000) # 충분한 학습을 위해 max_iter를 1,000으로 설정, 기본은 100\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train))) # train data 예측정확도\n",
    "print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) # test data 예측정확도\n",
    "\n",
    "# 모든 품사 69.5% => 명사/동사/형용사 71.2% 품사 선별이 도움이 되는 듯 => 모든 품사를 사용하되 품사 구별하도록 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['몰입/Noun', '하다/Verb', '없다/Adjective', './Punctuation', '어렵다/Adjective', '생각/Noun', '하다/Verb', '필요없다/Adjective', './Punctuation', '내/Noun', '가/Josa', '전투/Noun', '에/Josa', '참여/Noun', '한/Determiner', '듯/Noun', '손/Noun', '에/Josa', '땀/Noun', '이남/Noun', './Punctuation']\n"
     ]
    }
   ],
   "source": [
    "# 모든 품사를 사용하되 품사 구별하도록 \n",
    "\n",
    "def twit_tokenizer2(text):\n",
    "    result = []\n",
    "    for word, tag in okt.pos(text, norm=True, stem=True):\n",
    "        result.append('/'.join([word, tag])) #단어의 품사를 구분할 수 있도록 함\n",
    "    return result\n",
    "\n",
    "print(twit_tokenizer2(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.789\n",
      "#Test set score: 0.718\n"
     ]
    }
   ],
   "source": [
    "# 모든 품사를 사용하되 품사 구별하도록 \n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer2, max_features=2000, min_df=5, max_df=0.5)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000) # 충분한 학습을 위해 max_iter를 1,000으로 설정, 기본은 100\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train))) # train data 예측정확도\n",
    "print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) # test data 예측정확도\n",
    "\n",
    "# 명사/동사/형용사 71.2% => 모든 품사 사용 품사 구별 71.8%\n",
    "# 모든 품사 사용 69.5% => 모든 품사 사용 품사 구별 71.8%\n",
    "\n",
    "# 혹시 명사, 동사, 형용사만 선택하고 품사 구별하면??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Max alpha 1.600 at max validation score 0.727\n"
     ]
    }
   ],
   "source": [
    "# 앞에서 로지스틱 회귀분석, 이번에는 릿지 회귀분석 수행\n",
    "# 그리드서치로 최적 alpha 찾기\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_ridge, X_val_ridge, y_train_ridge, y_val_ridge = train_test_split(\n",
    "    X_train_tfidf, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "max_score = 0\n",
    "max_alpha = 0\n",
    "for alpha in np.arange(0.1, 10, 0.1): # alpha를 0.1부터 10까지 0.1씩 증가\n",
    "    ridge_clf = RidgeClassifier(alpha=alpha) #릿지 분류기 선언\n",
    "    ridge_clf.fit(X_train_ridge, y_train_ridge) #학습\n",
    "    score = ridge_clf.score(X_val_ridge, y_val_ridge) #검정 데이터셋에 대해 정확도를 측정\n",
    "    if score > max_score: #정확도가 이전의 정확도 최대값보다 크면 최대값을 변경한다.\n",
    "        max_score = score\n",
    "        max_alpha = alpha\n",
    "print('#Max alpha {:.3f} at max validation score {:.3f}'.format(max_alpha, max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Ridge Train set score: 0.807\n",
      "#Ridge Test set score: 0.726\n",
      "#Lasso Train set score: 0.703\n",
      "#Lasso Test set score: 0.696\n",
      "#Used features count: 956 out of 2000\n"
     ]
    }
   ],
   "source": [
    "# 최적 alpha로 릿지 수행, 라쏘도 수행 \n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "ridge_clf = RidgeClassifier(alpha=1.6)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "print('#Ridge Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Ridge Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=0.5)\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "print('#Lasso Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Lasso Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "print('#Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1])\n",
    "\n",
    "# 로지스틱, 모든 품사 사용 품사 구별 71.8% => 릿지, 모든 품사 사용 품사 구별 72.6%\n",
    "# 라쏘는 69.6%로 성능이 별로. 특성 2,000개 중 956개만 남아."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.768\n",
      "Test set score: 0.704\n"
     ]
    }
   ],
   "source": [
    "# 나이브베이즈 수행\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB_clf = MultinomialNB(alpha=0.1)\n",
    "NB_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "# 영어 데이터와 달리, 나이브베이즈가 로지스틱 보다도 낮은 결과\n",
    "# 나이브베이즈가 항상 좋은 결과를 보이는 것은 아니라는 사실을 알 수 있음.\n",
    "\n",
    "# 최고 성능을 얻으려면 다양한 모형과 세팅을 모두 시도해볼 수밖에 없음 :)\n",
    "\n",
    "# 영어 데이터에서와 같이 max_features=2000 제한 없이 돌리면??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM을 이용한 문서 분류\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.897\n",
      "Test set score: 0.694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(C=1.0, kernel='rbf', gamma='scale') # defalut values\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('Train set score: {:.3f}'.format(svm.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(svm.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[참고] 성능 척도 F1 Score \n",
    "정확도(accuracy)(= 맞게 예측한 데이터 건수 / 전체 예측 데이터 건수)는 불균형(imbalanced)한 레이블 값 분포에서 모델의 성능을 판단할 때 적합하지 않은 면이 있음.  \n",
    "F1 Score는 주로 분류 클래스 간의 데이터 불균형이 심각할때 사용\n",
    "\n",
    "https://velog.io/@ljs7463/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80%EC%A0%95%EB%B0%80%EB%8F%84%EC%9E%AC%ED%98%84%EC%9C%A8f1-score%EB%93%B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_true, y_pred))\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_true, y_pred, average=['micro', 'macro', 'weighted’ 중 하나 선택])\n",
    "\n",
    "# 'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "# 'macro': Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account. \n",
    "# 'weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). \n",
    "#             This alters ‘macro’ to account for label imbalance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
