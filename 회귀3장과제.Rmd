---
---

```{r}
#3.4
#a) Prepare a dot plot for the number of copiers serviced X1. What information is provided by this plot? Are there any outlying cases with respect to this variable? 
t04 <- read.table("CH01PR20.txt")
names(t04)<-c("Y","X")
#with(plot(X, freq(X)),data=t04) #왜 안되지
X1<-c(1,2,3,4,5,6,7,8,9,10)
Y1<-c(4,8,2,5,8,2,6,3,4,3)
plot(X1, Y1, xlab = "X", ylab = "frequency")
#b) The cases are given in time order. Prepare a time plot for the number of copiers serviced. What does your plot show? 
with(plot(X, xlab = "Time order", ylab = "X"),data=t04)
with(lines(X,xlab="Time order", ylab = "X"),data=t04)
#c) Prepare a stem-and-leaf plot of the residuals. Are there any noteworthy features in this plot?
#residaul 할때 lm 붙이기
t04.lm<-lm(Y~X, data=t04)
stem(t04.lm$resid)
#d) Prepare residual plots of ei versus Yi_hat and el versus Xi on separate graphs. Do these plots provide the same information? What departures from regression model (2.1) can be studied from these plots? State your findings. 
par(mfrow=c(2,2))
with(plot(t04.lm$fitted, t04.lm$resid,xlab = "fitted value", ylab="Residual"), data=t04)
par(mfrow=c(2,2))
with(plot(t04.lm$fitted, t04.lm$resid,xlab = "fitted value", ylab="Residual"), data=t04)
with(plot(X, t04.lm$resid,xlab = "predictor", ylab="Residual"), data=t04)
#e) Prepare a normal probability plot of the residuals. Also obtain the coefficient of correlation between the ordered residuals and their expected values under normality. Does the normality assumption appear to be tenable here? Use Table B.6 and a = .10. 
t04 <- read.table("CH01PR20.txt")
names(t04)<-c("Y","X")
t04.lm<-lm(Y~X, data=t04)
with(qqnorm(t04.lm$resid),data=t04)
ord.04<-order(t04.lm$resid)
resid.new<-t04.lm$resid[ord.04]
qq.res<-qqnorm(resid.new)
exp.x<-qq.res$x
ori.x<-qq.res$y
cor(ori.x, exp.x)
summary(t04.lm)
anova(t04.lm) #n=45
#f) Prepare a time plot of the residuals to ascertain whether the error terms are correlated over time. What is your conclusion?
with(plot(abs(t04.lm$resid), xlab = "Time order", ylab = "Absolute residual"),data=t04)
with(lines(abs(t04.lm$resid)), data=t04)
#g) Assume that (3.10) is applicable and conduct the Breusch-Pagan test to determine whether or not the error variance varies with the level of X. Use a = .05. State the alternatives, decision rule, and conclusion.
library(car)
ncvTest(t04.lm)
qchisq(0.95,1)
#h) Information is given below on two variables not included in the regression model, namely, mean operational age of copiers serviced on the call (X2' in months) and years of experience ofthe service person making the call (X3). Plot the residuals against X2 and X3 on separate - graphs to ascertain whether the model can be improved by including either or both of these variables. What do you conclude? 
t04h <- read.table("CH01PR04.txt")
names(t04h) <- c("Y","X1","X2","X3")
resid.2.lm <- lm(Y~X2, data = t04h)
resid.3.lm <- lm(Y~X3, data = t04h)
with(plot(X2, resid.2.lm$resid, xlab = "X2", ylab="Residual"),data=t04h)
with(plot(X3, resid.3.lm$resid, xlab = "X3", ylab="Residual"),data=t04h)

#3.6
#a) Obtain the residuals ei and prepare a box plot of the residuals. What information is provided by your plot? 
t06 <- read.table("CH01PR22.txt")
names(t06)<-x("Y","X")
t06.lm$resid
summary(t06.lm$resid)
boxplot(t06.lm$resid, ylim=c(-6,6),ylab="Residual")
#b) Plot the residuals ei against the fitted values Y; to ascertain whether any departures from regression model (2.1) are evident. State your findings
with(plot(t06.lm$fitted, t06.lm$resid, xlab="fitted value", ylab = "residual"), data=t06)
#c) Prepare a normal probability plot ofthe residuals. Also obtain the coefficient of correlation between the ordered residuals and their expected values under normality. Does the normality assumption appear to be reasonable here? Use Table B.6 and ex = .05.
with(qqnotm(t06.lm$resid),data=t06)
ord.o6<-order(t06.lm$resid)
resid.new<-t06.lm$resid[ord.06]
MSE<-sum(t06.lm$redis^2)/(n-2)
EVN<-sqrt(MSE)*qnorm((rank(resid.new)-0.375)/((n)+0.25))
t06.lm.new<-lm(EVN~resid.new, data = t06)
anova(t06.lm.new)
RR<-141.302/(141.302+2.383)
SXY<-sum((resid.new-mean(resid.new))*(RVN-mean(EVN)))
SXY>0
r.06<-sqrt(RR)
r.06
#d) Compare the frequencies of the residuals against the expected frequencies under normality, using the 25th, 50th, and 75th percentiles of the relevant t distribution. Is the information provided by these comparisons consistent with the findings from the normal probability plot in part (c)?
rt.06<-0.992*sqrt(n-2)/sqrt(1-(0.991)^2)
rt.06
qt(0.25,n-2)
qt(0.5,n-2)
qt(0.75,n-2)

#e). Use the Brown-Forsythe test to determine whether or not the error variance varies with the level of X. Divide the data into the two groups, X :::: 24, X > 24, and use ex = .05. State the decision rule and conclusion. Does your conclusion support your preliminary findings in part (b)? 
d1 <- abs(resid[ta01$X<=24] - median(resid[ta01$X<=24]))
d2 <- abs(resid[ta01$X>24] - median(resid[ta01$X>24]))
ds <- c(d1,d2)
t.test(d1,d2, var.eqaul=TRUE)
mean(d1)
mean(d2)
S <-sqrt((sum((d1-mean(d1))^2)+sum((d2-mean(d2))^2))/(n-2))
(mean(d1)-mean(d2))/(S*0.5)
qt(0.975, n-2)
#3.11
#a) Plot the residuals ei against Xi' What conclusions do you draw from the plot?
t11<-read.table(".txt")
names(t11)<-c("X", "resid.ll")
with(plot(X,resid.ll,xlab="predictor", ylab="Residual"),data=t11)
#b)  Assume that (3.10) is applicable and conduct the Breusch-Pagan test to determine whether or not the error variance vari~ with log-dose of the grug (X). Use ex = .05. State the alternatives, decision rule, and conclusion. Does your conclusion support your preliminary findings in part (a)?
SSE<-sum(resid.ll^2)
SSE
fitl<-lm(resid.ll^2~X, data=tll)
anova(fitl)
(330.04/2)/(SSE/n)^2
#3.14
#a) Perform the F test to determine whether or not there is lack of fit of a linear regression function; use ex = .01. State the alternatives, decision rule, and conclusion.
t14<-read.table(".txt")
names(t14)<-c("Y","X")
full<-lm(Y~factor(X),data=t14)
smaller<-lm(Y~X,data=t14)
anova(smaller, full)
((146-128)/(14-12))/(128/12)
qf(0.95,2,12)
#b)  Is there any advantage of having an equal number of replications at each of1he X levels? Is there any disadvantage?
#c) Does the test in part (a) indicate what regression function is appropriate when it leads to the conclusion that the regression function is not linear? How would you proceed? 
#3.17
#a) Prepare a scatter plot of the data. Does a linear relation appear adequate here?
t17<-read.table(".txt")
names(t17)<-c("Y","X")
with(plot(X,Y),data = t17)
#b)  Use the Box-Cox procedure and standardization (3.36) to find an appropriate power transformation of Y. Evaluate SSE for A = .3, .4, .5, .6, .7. What transformation of Y is suggested?
boxCox(t17.lm,c(-0.2,-0.1,0,0.1,0.2))
#c) Use the transformation Y' = sqrt(Y) and obtain the estimated linear regression function for the transformed data.
new.Y<-sqrt(t17$Y)
t17.lm2<-lm(new.Y~X,data = t17)
summary(t17.lm2)
#d)Plot the estimated regression line and the transformed data. Does the regression line appear to be a good fit to the transformed data? 
with(plot(X, new.Y, ylab = "sqrt(Y)"),data=t17)
abline(10.26,1.07,col=2, lwd=2)
#e) Obtain the residuals and plot them against the fitted values. Also prepare a normal probability plot. What do your plots show? 
t17<-read.table(".txt")
names(t17)<-c("Y","X")
t17.lm<-lm(Y~X,dat=t17)
with(plot(t17.lm$fitted,t17.lm$resid, xlab = "fitted value", ylab="Residual"),data=t17)
with(qqnorm(t17.lm$resid),data=t17)
#f)Express the estimated regression function in the original units. 

#3.18
#a) Prepare a scatter plot of the data Does a linear relation appear adequate here? Would a transformation on X or Y be more appropriate here? Why?
t18<-read.table(".txt")
names(t18)<-c("Y","X")
with(plot(X,Y), data = t18)
#b) Use the transformation X' = sqrt(X) and obtain the estimated linear regression function for the transformed data
new.X<-sqrt(t18$X)
t18.lm.new<-lm(Y~new.X, data=t18)
summary(t18.lm.new)
#c)  Plot the estimated regression line and the transformed data. Does the regression line appear to be a good fit to the transformed data?
with(plot(new.X,Y, xlab = "sqrt(X)", ylab="Y"),data=t18)
abline(t18.lm.new,col=2,lwd=2)
#d) Obtain the residuals and plot them against the fitted values. Also prepare a normal probability plot. What do your plots show? 
t18.lm.new$resid
with(qqnorm(t18.lm.new$resid), data=t18)
#e)  Express the estimated regression function in the original units


#4번
#a)
sc<-read.table("Solution concentration.txt")
names(sc)<-c("Y","X")
summary(sc)

#b)
full<-lm(Y~factor(X),data=sc)
smaller<-lm(Y~X,data=sc)
anova(smaller, full)
(( 2.9247-0.1574 )/(13-10))/(0.1574 /10)
qf(0.95,3,10)
#c)
#d)
with(plot(X,Y),data = sc)
#e)
sc.lm<-lm(Y~X,data=sc)
library(MASS)
boxCox(sc.lm,c(-0.2,-0.1,0,0.1,0.2))
#f)

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
